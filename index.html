<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no, maximum-scale=1.0">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="theme-color" content="#000000">
    <title>BlindGuide</title>
    <link rel="manifest" href="manifest.json">
    
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; -webkit-tap-highlight-color: transparent; user-select: none; }
        html, body { height: 100%; overflow: hidden; background: #000; color: #fff; font-family: -apple-system, sans-serif; }
        
        .app { height: 100dvh; display: flex; flex-direction: column; }
        #video { position: absolute; opacity: 0; pointer-events: none; width: 1px; height: 1px; }
        
        .touch-area { flex: 1; display: flex; flex-direction: column; }
        
        .zone { flex: 1; display: flex; align-items: center; justify-content: center; flex-direction: column; gap: 8px; }
        .zone-top { border-bottom: 3px solid #333; }
        .zone-bottom { border-top: 3px solid #333; }
        .zone:active { background: #222; }
        
        .zone-label { font-size: 20px; font-weight: 700; text-align: center; padding: 10px; opacity: 0.7; }
        .zone-voice { font-size: 13px; color: #4488ff; opacity: 0.8; }
        
        .status-area { position: relative; }
        .status-circle {
            width: 120px; height: 120px; border-radius: 50%;
            display: flex; align-items: center; justify-content: center;
            font-size: 45px; transition: all 0.3s;
        }
        .status-circle.safe { background: rgba(0,255,136,0.2); border: 4px solid #0f8; }
        .status-circle.warning { background: rgba(255,170,0,0.2); border: 4px solid #fa0; animation: pulse 1s infinite; }
        .status-circle.danger { background: rgba(255,68,68,0.3); border: 4px solid #f44; animation: pulse 0.3s infinite; }
        .status-circle.listening { background: rgba(68,136,255,0.3); border: 4px solid #48f; animation: pulse 0.8s infinite; }
        
        @keyframes pulse { 0%,100% { transform: scale(1); } 50% { transform: scale(1.08); } }
        
        .listening-indicator {
            position: absolute;
            bottom: -35px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 14px;
            color: #4488ff;
            font-weight: 600;
            opacity: 0;
            transition: opacity 0.3s;
            white-space: nowrap;
        }
        .listening-indicator.active { opacity: 1; }
        
        .direction { position: absolute; font-size: 50px; opacity: 0; transition: opacity 0.2s; }
        .direction.left { left: 15px; top: 50%; transform: translateY(-50%); }
        .direction.right { right: 15px; top: 50%; transform: translateY(-50%); }
        .direction.active { opacity: 1; }
        
        .mic-btn {
            position: fixed;
            bottom: 25px;
            left: 50%;
            transform: translateX(-50%);
            background: #48f;
            border: none;
            padding: 15px 25px;
            border-radius: 30px;
            font-size: 16px;
            font-weight: 700;
            color: #fff;
            z-index: 10;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        .mic-btn.listening {
            background: #f44;
            animation: pulse 0.5s infinite;
        }
        
        .loading { position: fixed; inset: 0; background: #000; display: flex; flex-direction: column; align-items: center; justify-content: center; z-index: 100; transition: opacity 0.5s; }
        .loading.hidden { opacity: 0; pointer-events: none; }
        .loading-icon { font-size: 80px; animation: bounce 1s infinite; }
        @keyframes bounce { 0%,100% { transform: translateY(0); } 50% { transform: translateY(-15px); } }
        .loading-text { font-size: 18px; margin-top: 20px; text-align: center; padding: 0 20px; }
        
        .help { position: fixed; inset: 0; background: rgba(0,0,0,0.98); z-index: 50; display: none; flex-direction: column; padding: 20px 15px; overflow-y: auto; }
        .help.visible { display: flex; }
        .help-title { font-size: 22px; font-weight: 700; margin-bottom: 15px; text-align: center; }
        .help-section { font-size: 14px; font-weight: 700; color: #48f; margin: 12px 0 8px 0; }
        .help-item { padding: 10px; margin-bottom: 6px; background: #111; border-radius: 8px; }
        .help-row { display: flex; justify-content: space-between; align-items: center; }
        .help-gesture { font-size: 13px; font-weight: 600; }
        .help-voice { font-size: 12px; color: #4488ff; }
        .help-buttons { display: flex; gap: 10px; margin-top: 15px; }
        .help-btn { flex: 1; padding: 16px; border: none; border-radius: 12px; font-size: 15px; font-weight: 700; }
        .help-btn.tap { background: #333; color: #fff; }
        .help-btn.voice { background: #48f; color: #fff; }
        
        .ai-status {
            position: fixed;
            top: 10px;
            right: 10px;
            background: rgba(0,0,0,0.7);
            padding: 8px 12px;
            border-radius: 20px;
            font-size: 11px;
            z-index: 10;
        }
    </style>
</head>
<body>
    <div class="loading" id="loading">
        <div class="loading-icon">ü¶Æ</div>
        <div class="loading-text" id="loadingText">Starting BlindGuide...</div>
    </div>
    
    <div class="help" id="help">
        <div class="help-title">ü¶Æ BlindGuide Help</div>
        
        <div class="help-section">üìç Describe Area</div>
        <div class="help-item">
            <div class="help-row">
                <span class="help-gesture">TAP TOP</span>
                <span class="help-voice">Say: "What's around"</span>
            </div>
        </div>
        
        <div class="help-section">‚úì Check Safety</div>
        <div class="help-item">
            <div class="help-row">
                <span class="help-gesture">TAP BOTTOM</span>
                <span class="help-voice">Say: "Is it safe"</span>
            </div>
        </div>
        
        <div class="help-section">üß† AI Scan (stairs, doors, hazards)</div>
        <div class="help-item">
            <div class="help-row">
                <span class="help-gesture">DOUBLE TAP</span>
                <span class="help-voice">Say: "Scan" or "Check stairs"</span>
            </div>
        </div>
        
        <div class="help-section">‚Üê ‚Üí Check Sides</div>
        <div class="help-item">
            <div class="help-row">
                <span class="help-gesture">SWIPE LEFT/RIGHT</span>
                <span class="help-voice">Say: "Left" or "Right"</span>
            </div>
        </div>
        
        <div class="help-section">üé§ Voice Button</div>
        <div class="help-item">
            <div class="help-row">
                <span class="help-gesture">TAP MIC BUTTON</span>
                <span class="help-voice">Then speak command</span>
            </div>
        </div>
        
        <div class="help-section">ü§ñ Switch AI</div>
        <div class="help-item">
            <div class="help-row">
                <span class="help-gesture">‚Äî</span>
                <span class="help-voice">Say: "Use GPT" or "Use Claude"</span>
            </div>
        </div>
        
        <div class="help-buttons">
            <button class="help-btn tap" id="helpTap">TAP TO START</button>
            <button class="help-btn voice" id="helpVoice">üé§ SAY "START"</button>
        </div>
    </div>
    
    <div class="app">
        <video id="video" autoplay playsinline muted></video>
        
        <div class="ai-status" id="aiStatus">ü§ñ AI: Both</div>
        
        <div class="touch-area" id="touchArea">
            <div class="zone zone-top" id="zoneTop">
                <div class="zone-label">üëÜ TAP HERE<br>DESCRIBE AREA</div>
                <div class="zone-voice">or say "What's around"</div>
            </div>
            <div class="zone zone-middle">
                <div class="direction left" id="hintLeft">‚Üê</div>
                <div class="direction right" id="hintRight">‚Üí</div>
                <div class="status-area">
                    <div class="status-circle safe" id="status">‚úì</div>
                    <div class="listening-indicator" id="listeningIndicator">üé§ Listening...</div>
                </div>
            </div>
            <div class="zone zone-bottom" id="zoneBottom">
                <div class="zone-label">üëá TAP HERE<br>IS IT SAFE?</div>
                <div class="zone-voice">or say "Is it safe"</div>
            </div>
        </div>
        
        <button class="mic-btn" id="micBtn">üé§ TAP TO SPEAK</button>
    </div>

    <!-- TensorFlow.js + COCO-SSD -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    
    <script>
    const CONFIG = {
        WORKER_URL: "https://guidedog.kpremks.workers.dev",
        ZONES: { immediate: 0.8, close: 1.5, awareness: 3.0 },
        CRITICAL: ["car", "bus", "truck", "motorcycle", "bicycle", "train"],
        DANGER: ["person", "dog", "cat", "horse"],
        WARNING: ["chair", "bench", "couch", "bed", "dining table", "toilet", "refrigerator", "potted plant"]
    };
    
    const state = {
        model: null,
        video: null,
        isRunning: false,
        isPaused: false,
        detections: [],
        lastVoice: 0,
        lastVibrate: 0,
        touchStart: { x: 0, y: 0, time: 0 },
        lastTap: 0,
        longPressTimer: null,
        audioCtx: null,
        recognition: null,
        isListening: false,
        aiProvider: 'race' // 'openai', 'anthropic', or 'race'
    };
    
    // ========== SPEECH OUTPUT ==========
    function speak(text, interrupt = true) {
        if (!text) return;
        
        // Stop listening while speaking
        if (state.isListening) {
            stopListening();
        }
        
        try {
            if (interrupt) speechSynthesis.cancel();
            const u = new SpeechSynthesisUtterance(text);
            u.rate = 0.9;
            u.pitch = 1.0;
            u.volume = 1.0;
            speechSynthesis.speak(u);
            state.lastVoice = Date.now();
            console.log('üîä Speaking:', text);
        } catch (e) {
            console.error('Speech error:', e);
        }
    }
    
    // ========== SPEECH RECOGNITION ==========
    function initSpeechRecognition() {
        try {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                console.log('Speech recognition not supported');
                document.getElementById('micBtn').style.display = 'none';
                return false;
            }
            
            state.recognition = new SpeechRecognition();
            state.recognition.continuous = false;
            state.recognition.interimResults = false;
            state.recognition.lang = 'en-US';
            state.recognition.maxAlternatives = 1;
            
            state.recognition.onstart = () => {
                console.log('üé§ Recognition started');
                state.isListening = true;
                updateListeningUI(true);
            };
            
            state.recognition.onresult = (event) => {
                const text = event.results[0][0].transcript.toLowerCase().trim();
                const confidence = event.results[0][0].confidence;
                console.log('üé§ Heard:', text, 'Confidence:', confidence);
                
                state.isListening = false;
                updateListeningUI(false);
                
                // Process command
                handleVoiceCommand(text);
            };
            
            state.recognition.onend = () => {
                console.log('üé§ Recognition ended');
                state.isListening = false;
                updateListeningUI(false);
            };
            
            state.recognition.onerror = (e) => {
                console.log('üé§ Recognition error:', e.error);
                state.isListening = false;
                updateListeningUI(false);
                
                if (e.error === 'not-allowed') {
                    speak('Microphone access denied. Please enable microphone permission.');
                } else if (e.error === 'no-speech') {
                    speak('No speech detected. Tap the microphone and try again.');
                }
            };
            
            console.log('Speech recognition initialized');
            return true;
        } catch (e) {
            console.error('Speech recognition init error:', e);
            return false;
        }
    }
    
    function startListening() {
        if (!state.recognition) {
            speak('Voice commands not available on this device.');
            return;
        }
        
        if (state.isListening) {
            stopListening();
            return;
        }
        
        // Stop any ongoing speech
        speechSynthesis.cancel();
        
        try {
            state.recognition.start();
            vibrate([50]);
        } catch (e) {
            console.error('Start listening error:', e);
            // Recognition might already be running, try stopping and restarting
            try {
                state.recognition.stop();
                setTimeout(() => {
                    state.recognition.start();
                }, 100);
            } catch (e2) {
                console.error('Restart error:', e2);
            }
        }
    }
    
    function stopListening() {
        if (!state.recognition) return;
        
        try {
            state.recognition.stop();
        } catch (e) {}
        
        state.isListening = false;
        updateListeningUI(false);
    }
    
    function updateListeningUI(listening) {
        const indicator = document.getElementById('listeningIndicator');
        const micBtn = document.getElementById('micBtn');
        const status = document.getElementById('status');
        
        if (listening) {
            indicator.classList.add('active');
            micBtn.classList.add('listening');
            micBtn.innerHTML = 'üî¥ LISTENING...';
            status.classList.add('listening');
        } else {
            indicator.classList.remove('active');
            micBtn.classList.remove('listening');
            micBtn.innerHTML = 'üé§ TAP TO SPEAK';
            status.classList.remove('listening');
        }
    }
    
    function handleVoiceCommand(text) {
        console.log('Processing command:', text);
        vibrate([30]);
        
        // Normalize text
        const t = text.toLowerCase().replace(/[.,!?]/g, '');
        
        // HELP
        if (t.includes('help') || t.includes('commands') || t.includes('what can')) {
            showHelp();
            return;
        }
        
        // START (from help screen)
        if (t.includes('start') || t.includes('begin') || t.includes('go') || t.includes('ok')) {
            if (document.getElementById('help').classList.contains('visible')) {
                hideHelp();
                return;
            }
        }
        
        // STOP / PAUSE
        if (t.includes('stop') || t.includes('pause') || t.includes('quiet') || t.includes('shut')) {
            state.isPaused = true;
            speak('Navigation paused. Say resume to continue.');
            return;
        }
        
        // RESUME
        if (t.includes('resume') || t.includes('continue') || t.includes('unpause')) {
            state.isPaused = false;
            speak('Navigation resumed.');
            return;
        }
        
        // DESCRIBE / WHAT'S AROUND
        if (t.includes('around') || t.includes('describe') || t.includes('what do you see') || 
            t.includes('where am') || t.includes('surroundings') || t.includes('what is')) {
            describeScene();
            return;
        }
        
        // SAFETY CHECK
        if (t.includes('safe') || t.includes('clear') || t.includes('can i walk') || 
            t.includes('can i go') || t.includes('path')) {
            checkSafety();
            return;
        }
        
        // LEFT
        if (t.includes('left') && !t.includes('right')) {
            checkDirection('left');
            return;
        }
        
        // RIGHT
        if (t.includes('right') && !t.includes('left')) {
            checkDirection('right');
            return;
        }
        
        // AHEAD / FRONT
        if (t.includes('ahead') || t.includes('front') || t.includes('forward')) {
            checkDirection('ahead');
            return;
        }
        
        // AI SCAN / STAIRS / STEPS / DOORS
        if (t.includes('scan') || t.includes('analyze') || t.includes('stair') || 
            t.includes('step') || t.includes('door') || t.includes('detail') ||
            t.includes('obstacle') || t.includes('hazard')) {
            detailedScan();
            return;
        }
        
        // SWITCH TO OPENAI / GPT
        if (t.includes('openai') || t.includes('gpt') || (t.includes('use') && t.includes('open'))) {
            state.aiProvider = 'openai';
            updateAIStatus();
            speak('Switched to OpenAI.');
            return;
        }
        
        // SWITCH TO ANTHROPIC / CLAUDE
        if (t.includes('claude') || t.includes('anthropic')) {
            state.aiProvider = 'anthropic';
            updateAIStatus();
            speak('Switched to Claude.');
            return;
        }
        
        // USE BOTH
        if (t.includes('both') || t.includes('fastest') || t.includes('race') || t.includes('auto')) {
            state.aiProvider = 'race';
            updateAIStatus();
            speak('Using both AI providers.');
            return;
        }
        
        // WHICH AI
        if (t.includes('which ai') || t.includes('what ai') || t.includes('current')) {
            const provider = state.aiProvider === 'race' ? 'both providers' : state.aiProvider;
            speak(`Currently using ${provider}.`);
            return;
        }
        
        // REPEAT
        if (t.includes('repeat') || t.includes('again') || t.includes('what did')) {
            describeScene();
            return;
        }
        
        // If nothing matched, try to be helpful
        speak(`I heard "${text}". Try: what's around, is it safe, scan for stairs, left, or right.`);
    }
    
    function updateAIStatus() {
        const el = document.getElementById('aiStatus');
        const labels = { 'openai': 'GPT-4', 'anthropic': 'Claude', 'race': 'Both' };
        el.textContent = 'ü§ñ AI: ' + labels[state.aiProvider];
    }
    
    // ========== VIBRATION ==========
    function vibrate(pattern) {
        const now = Date.now();
        if (now - state.lastVibrate < 200) return;
        state.lastVibrate = now;
        try { navigator.vibrate?.(pattern); } catch (e) {}
    }
    
    // ========== AUDIO ==========
    function initAudio() {
        try { 
            state.audioCtx = new (window.AudioContext || window.webkitAudioContext)(); 
        } catch (e) {}
    }
    
    function playTone(freq, dur, pan = 0) {
        if (!state.audioCtx) return;
        try {
            if (state.audioCtx.state === 'suspended') state.audioCtx.resume();
            const osc = state.audioCtx.createOscillator();
            const gain = state.audioCtx.createGain();
            const panner = state.audioCtx.createStereoPanner();
            osc.frequency.value = freq;
            gain.gain.setValueAtTime(0.3, state.audioCtx.currentTime);
            gain.gain.exponentialRampToValueAtTime(0.01, state.audioCtx.currentTime + dur);
            panner.pan.value = pan;
            osc.connect(gain).connect(panner).connect(state.audioCtx.destination);
            osc.start();
            osc.stop(state.audioCtx.currentTime + dur);
        } catch (e) {}
    }
    
    // ========== AI ANALYSIS ==========
    async function callAI(imageData, provider) {
        try {
            const response = await fetch(CONFIG.WORKER_URL, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ image: imageData, provider: provider })
            });
            
            if (!response.ok) {
                console.error('AI response not ok:', response.status);
                return null;
            }
            
            const data = await response.json();
            console.log(`AI ${provider} response:`, data);
            return data.result || null;
        } catch (e) {
            console.error(`AI ${provider} error:`, e);
            return null;
        }
    }
    
    async function analyzeWithAI() {
        try {
            // Capture frame
            const canvas = document.createElement('canvas');
            canvas.width = 640;  // Higher res for better stair detection
            canvas.height = 480;
            canvas.getContext('2d').drawImage(state.video, 0, 0, 640, 480);
            const imageData = canvas.toDataURL('image/jpeg', 0.7).split(',')[1];
            
            const mode = state.aiProvider;
            
            if (mode === 'openai') {
                return await callAI(imageData, 'openai');
            }
            
            if (mode === 'anthropic') {
                return await callAI(imageData, 'anthropic');
            }
            
            // Race mode - try both
            if (mode === 'race') {
                const results = await Promise.allSettled([
                    callAI(imageData, 'openai'),
                    callAI(imageData, 'anthropic')
                ]);
                
                // Get first successful result
                for (const r of results) {
                    if (r.status === 'fulfilled' && r.value) {
                        return r.value;
                    }
                }
                return null;
            }
            
            return null;
        } catch (e) {
            console.error('AI analysis error:', e);
            return null;
        }
    }
    
    // ========== OBJECT DETECTION (local) ==========
    async function detect() {
        if (!state.model || !state.video) return [];
        
        try {
            const predictions = await state.model.detect(state.video);
            
            return predictions.map(p => {
                const cx = (p.bbox[0] + p.bbox[2] / 2) / state.video.videoWidth;
                const size = Math.max(p.bbox[2], p.bbox[3]) / Math.max(state.video.videoWidth, state.video.videoHeight);
                
                let position = 'ahead';
                if (cx < 0.33) position = 'left';
                else if (cx > 0.67) position = 'right';
                
                let depth = 5.0;
                if (size > 0.5) depth = 0.5;
                else if (size > 0.35) depth = 1.0;
                else if (size > 0.2) depth = 1.5;
                else if (size > 0.1) depth = 2.5;
                else if (size > 0.05) depth = 4.0;
                
                let priority = 'info';
                if (CONFIG.CRITICAL.includes(p.class)) priority = 'critical';
                else if (CONFIG.DANGER.includes(p.class)) priority = 'danger';
                else if (CONFIG.WARNING.includes(p.class)) priority = 'warning';
                
                return { name: p.class, position, depth, priority, inPath: cx > 0.25 && cx < 0.75 };
            }).sort((a, b) => {
                const p = { critical: 0, danger: 1, warning: 2, info: 3 };
                return (p[a.priority] - p[b.priority]) || (a.depth - b.depth);
            });
        } catch (e) {
            return [];
        }
    }
    
    // ========== ACTIONS ==========
    async function describeScene() {
        vibrate([30]);
        speak('Scanning...');
        
        // Use AI for description - it can see stairs, doors, etc.
        const aiResult = await analyzeWithAI();
        
        if (aiResult) {
            speak(aiResult);
            return;
        }
        
        // Fallback to local detection
        const detections = await detect();
        
        if (detections.length === 0) {
            speak('Area appears clear. Use AI scan for stairs and doors.');
            updateStatus('safe');
            return;
        }
        
        let desc = '';
        const ahead = detections.filter(d => d.position === 'ahead');
        const left = detections.filter(d => d.position === 'left');
        const right = detections.filter(d => d.position === 'right');
        
        if (ahead.length) desc += `${ahead[0].name} ahead. `;
        if (left.length) desc += `${left[0].name} on left. `;
        if (right.length) desc += `${right[0].name} on right. `;
        
        speak(desc || 'Objects detected nearby.');
    }
    
    async function checkSafety() {
        vibrate([30]);
        speak('Checking safety...');
        
        // Always use AI for safety - it can detect stairs!
        const aiResult = await analyzeWithAI();
        
        if (aiResult) {
            // Check if AI found dangers
            const lower = aiResult.toLowerCase();
            if (lower.includes('stair') || lower.includes('step') || lower.includes('danger') || 
                lower.includes('stop') || lower.includes('careful') || lower.includes('caution')) {
                vibrate([200, 100, 200]);
                updateStatus('danger');
            } else if (lower.includes('clear') || lower.includes('safe')) {
                vibrate([50, 30, 50]);
                updateStatus('safe');
            } else {
                updateStatus('warning');
            }
            speak(aiResult);
            return;
        }
        
        // Fallback
        const detections = await detect();
        const inPath = detections.filter(d => d.inPath);
        
        if (inPath.length === 0) {
            vibrate([50, 30, 50]);
            speak('No obstacles detected. But use AI scan to check for stairs.');
            updateStatus('safe');
        } else {
            vibrate([100, 50, 100]);
            speak(`${inPath[0].name} in your path. Proceed with caution.`);
            updateStatus('warning');
        }
    }
    
    async function checkDirection(dir) {
        vibrate([30]);
        
        // Show direction hint
        if (dir === 'left' || dir === 'right') {
            const hintEl = document.getElementById(`hint${dir.charAt(0).toUpperCase() + dir.slice(1)}`);
            if (hintEl) {
                hintEl.classList.add('active');
                setTimeout(() => hintEl.classList.remove('active'), 800);
            }
        }
        
        speak(`Checking ${dir}...`);
        
        // Use AI for comprehensive check
        const aiResult = await analyzeWithAI();
        
        if (aiResult) {
            speak(aiResult);
            return;
        }
        
        // Fallback to local
        const detections = await detect();
        const items = detections.filter(d => d.position === dir || (dir === 'ahead' && d.position === 'ahead'));
        
        if (items.length === 0) {
            speak(`Nothing detected on your ${dir}.`);
        } else {
            speak(`${items[0].name} on your ${dir}.`);
        }
    }
    
    async function detailedScan() {
        vibrate([30]);
        speak('Running AI scan for stairs, doors, and hazards...');
        
        const result = await analyzeWithAI();
        
        if (result) {
            // Check for critical info
            const lower = result.toLowerCase();
            if (lower.includes('stair') || lower.includes('step')) {
                vibrate([200, 100, 200, 100, 200]);
                updateStatus('danger');
            } else if (lower.includes('door')) {
                vibrate([100, 50, 100]);
                updateStatus('warning');
            }
            speak(result);
        } else {
            speak('AI scan complete. Could not analyze scene. Please try again.');
        }
    }
    
    // ========== STATUS ==========
    function updateStatus(status) {
        const el = document.getElementById('status');
        el.className = `status-circle ${status}`;
        el.textContent = status === 'safe' ? '‚úì' : status === 'warning' ? '!' : '‚ö†';
    }
    
    // ========== AUTO NAVIGATION ==========
    async function processNavigation() {
        if (!state.isRunning || state.isPaused) {
            setTimeout(processNavigation, 1000);
            return;
        }
        
        const detections = await detect();
        state.detections = detections;
        
        const threat = detections.find(d => d.inPath && (d.priority === 'critical' || d.priority === 'danger'));
        
        if (threat && threat.depth < CONFIG.ZONES.immediate) {
            updateStatus('danger');
            playTone(1000, 0.15, threat.position === 'left' ? -0.8 : threat.position === 'right' ? 0.8 : 0);
            vibrate([150, 80, 150]);
            
            const now = Date.now();
            if (now - state.lastVoice > 4000) {
                const dir = threat.position === 'left' ? 'right' : threat.position === 'right' ? 'left' : 'back';
                speak(`Stop! ${threat.name}! Go ${dir}!`);
            }
        } else if (threat && threat.depth < CONFIG.ZONES.close) {
            updateStatus('warning');
            playTone(700, 0.1, threat.position === 'left' ? -0.8 : threat.position === 'right' ? 0.8 : 0);
        } else if (!state.isListening) {
            updateStatus('safe');
        }
        
        setTimeout(processNavigation, 600);
    }
    
    // ========== GESTURES ==========
    function setupGestures() {
        const area = document.getElementById('touchArea');
        
        area.addEventListener('touchstart', e => {
            const t = e.touches[0];
            state.touchStart = { x: t.clientX, y: t.clientY, time: Date.now() };
            state.longPressTimer = setTimeout(() => {
                vibrate([30]);
                showHelp();
            }, 2000);
        }, { passive: true });
        
        area.addEventListener('touchmove', () => {
            clearTimeout(state.longPressTimer);
        }, { passive: true });
        
        area.addEventListener('touchend', e => {
            clearTimeout(state.longPressTimer);
            
            const t = e.changedTouches[0];
            const dx = t.clientX - state.touchStart.x;
            const dy = t.clientY - state.touchStart.y;
            const duration = Date.now() - state.touchStart.time;
            
            if (duration > 1500) return;
            
            // Swipe
            if (Math.abs(dx) > 60 && Math.abs(dx) > Math.abs(dy)) {
                checkDirection(dx > 0 ? 'right' : 'left');
                return;
            }
            
            // Double tap
            const now = Date.now();
            if (now - state.lastTap < 400) {
                detailedScan();
                state.lastTap = 0;
                return;
            }
            state.lastTap = now;
            
            // Single tap zones
            const y = t.clientY / window.innerHeight;
            if (y < 0.35) {
                describeScene();
            } else if (y > 0.65) {
                checkSafety();
            }
        }, { passive: true });
        
        // Microphone button
        document.getElementById('micBtn').addEventListener('click', (e) => {
            e.stopPropagation();
            startListening();
        });
    }
    
    // ========== HELP ==========
    function showHelp() {
        document.getElementById('help').classList.add('visible');
        stopListening();
        
        speak('Help. Tap top to describe area. Tap bottom to check safety. Double tap for AI scan to find stairs and doors. Swipe left or right to check sides. Tap microphone button then speak a command. Say start to begin.');
    }
    
    function hideHelp() {
        document.getElementById('help').classList.remove('visible');
        vibrate([50, 30, 50]);
        speak('BlindGuide ready. I will alert you to obstacles. Tap microphone to speak commands. Say scan to check for stairs.');
        state.isRunning = true;
        state.isPaused = false;
        processNavigation();
    }
    
    // ========== INIT ==========
    async function init() {
        state.video = document.getElementById('video');
        initAudio();
        const hasVoice = initSpeechRecognition();
        setupGestures();
        
        document.getElementById('helpTap').addEventListener('click', hideHelp);
        document.getElementById('helpVoice').addEventListener('click', () => {
            startListening();
        });
        
        document.getElementById('loadingText').textContent = 'Loading AI...';
        
        try {
            state.model = await cocoSsd.load();
            console.log('COCO-SSD model loaded');
        } catch (e) {
            console.error('Model error:', e);
        }
        
        document.getElementById('loadingText').textContent = 'Starting camera...';
        
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment', width: { ideal: 640 }, height: { ideal: 480 } },
                audio: false
            });
            state.video.srcObject = stream;
            await state.video.play();
        } catch (e) {
            speak('Camera required. Please allow camera and refresh.');
            return;
        }
        
        document.getElementById('loading').classList.add('hidden');
        updateAIStatus();
        
        // First time
        if (!localStorage.getItem('blindguide_v5')) {
            localStorage.setItem('blindguide_v5', 'true');
            showHelp();
        } else {
            speak('BlindGuide ready. Tap microphone to speak. Say scan to check for stairs.');
            state.isRunning = true;
            processNavigation();
        }
    }
    
    window.addEventListener('load', init);
    
    document.addEventListener('visibilitychange', () => {
        if (document.hidden) {
            state.isRunning = false;
            stopListening();
        } else {
            state.isRunning = true;
            processNavigation();
        }
    });
    
    if ('serviceWorker' in navigator) {
        navigator.serviceWorker.register('sw.js').catch(() => {});
    }
    </script>
</body>
</html>
