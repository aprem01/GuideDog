<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no, maximum-scale=1.0">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="theme-color" content="#000000">
    <title>BlindGuide</title>
    <link rel="manifest" href="manifest.json">
    
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; -webkit-tap-highlight-color: transparent; user-select: none; }
        html, body { height: 100%; overflow: hidden; background: #000; color: #fff; font-family: -apple-system, sans-serif; }
        
        .app { height: 100dvh; display: flex; flex-direction: column; }
        #video { position: absolute; opacity: 0; pointer-events: none; width: 1px; height: 1px; }
        
        .touch-area { flex: 1; display: flex; flex-direction: column; }
        
        .zone { flex: 1; display: flex; align-items: center; justify-content: center; flex-direction: column; gap: 10px; }
        .zone-top { border-bottom: 3px solid #333; }
        .zone-bottom { border-top: 3px solid #333; }
        .zone:active { background: #222; }
        
        .zone-label { font-size: 22px; font-weight: 700; text-align: center; padding: 15px; opacity: 0.7; }
        .zone-voice { font-size: 14px; color: #4488ff; opacity: 0.8; }
        
        .status-area { position: relative; }
        .status-circle {
            width: 120px; height: 120px; border-radius: 50%;
            display: flex; align-items: center; justify-content: center;
            font-size: 45px; transition: all 0.3s;
        }
        .status-circle.safe { background: rgba(0,255,136,0.2); border: 4px solid #0f8; }
        .status-circle.warning { background: rgba(255,170,0,0.2); border: 4px solid #fa0; animation: pulse 1s infinite; }
        .status-circle.danger { background: rgba(255,68,68,0.3); border: 4px solid #f44; animation: pulse 0.3s infinite; }
        .status-circle.listening { background: rgba(68,136,255,0.3); border: 4px solid #48f; animation: pulse 0.5s infinite; }
        
        @keyframes pulse { 0%,100% { transform: scale(1); } 50% { transform: scale(1.08); } }
        
        .listening-indicator {
            position: absolute;
            bottom: -40px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 14px;
            color: #4488ff;
            font-weight: 600;
            opacity: 0;
            transition: opacity 0.3s;
        }
        .listening-indicator.active { opacity: 1; }
        
        .direction { position: absolute; font-size: 60px; opacity: 0; transition: opacity 0.2s; }
        .direction.left { left: 15px; top: 50%; transform: translateY(-50%); }
        .direction.right { right: 15px; top: 50%; transform: translateY(-50%); }
        .direction.active { opacity: 1; }
        
        .mic-hint {
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(68,136,255,0.2);
            border: 2px solid #48f;
            padding: 12px 20px;
            border-radius: 30px;
            font-size: 14px;
            z-index: 10;
        }
        
        .loading { position: fixed; inset: 0; background: #000; display: flex; flex-direction: column; align-items: center; justify-content: center; z-index: 100; transition: opacity 0.5s; }
        .loading.hidden { opacity: 0; pointer-events: none; }
        .loading-icon { font-size: 80px; animation: bounce 1s infinite; }
        @keyframes bounce { 0%,100% { transform: translateY(0); } 50% { transform: translateY(-15px); } }
        .loading-text { font-size: 18px; margin-top: 20px; text-align: center; padding: 0 20px; }
        
        .help { position: fixed; inset: 0; background: rgba(0,0,0,0.98); z-index: 50; display: none; flex-direction: column; padding: 25px 15px; overflow-y: auto; }
        .help.visible { display: flex; }
        .help-title { font-size: 24px; font-weight: 700; margin-bottom: 20px; text-align: center; }
        .help-section { font-size: 16px; font-weight: 700; color: #48f; margin: 15px 0 10px 0; }
        .help-item { padding: 12px; margin-bottom: 8px; background: #111; border-radius: 10px; display: flex; justify-content: space-between; align-items: center; }
        .help-gesture { font-size: 14px; font-weight: 600; flex: 1; }
        .help-or { color: #666; margin: 0 10px; font-size: 12px; }
        .help-voice { font-size: 13px; color: #4488ff; flex: 1; text-align: right; }
        .help-action { font-size: 12px; color: #888; margin-top: 5px; width: 100%; }
        .help-buttons { display: flex; gap: 10px; margin-top: 20px; }
        .help-btn { flex: 1; padding: 18px; border: none; border-radius: 12px; font-size: 16px; font-weight: 700; }
        .help-btn.tap { background: #333; color: #fff; }
        .help-btn.voice { background: #48f; color: #fff; }
    </style>
</head>
<body>
    <div class="loading" id="loading">
        <div class="loading-icon">ü¶Æ</div>
        <div class="loading-text" id="loadingText">Starting BlindGuide...</div>
    </div>
    
    <div class="help" id="help">
        <div class="help-title">ü¶Æ BlindGuide Help</div>
        
        <div class="help-section">üìç Describe Area</div>
        <div class="help-item">
            <span class="help-gesture">TAP TOP</span>
            <span class="help-or">or say</span>
            <span class="help-voice">"What's around"</span>
        </div>
        
        <div class="help-section">‚úì Check Safety</div>
        <div class="help-item">
            <span class="help-gesture">TAP BOTTOM</span>
            <span class="help-or">or say</span>
            <span class="help-voice">"Is it safe"</span>
        </div>
        
        <div class="help-section">üß† AI Scan (stairs, doors)</div>
        <div class="help-item">
            <span class="help-gesture">DOUBLE TAP</span>
            <span class="help-or">or say</span>
            <span class="help-voice">"Scan" or "Analyze"</span>
        </div>
        
        <div class="help-section">‚Üê Check Left Side</div>
        <div class="help-item">
            <span class="help-gesture">SWIPE LEFT</span>
            <span class="help-or">or say</span>
            <span class="help-voice">"What's on left"</span>
        </div>
        
        <div class="help-section">‚Üí Check Right Side</div>
        <div class="help-item">
            <span class="help-gesture">SWIPE RIGHT</span>
            <span class="help-or">or say</span>
            <span class="help-voice">"What's on right"</span>
        </div>
        
        <div class="help-section">‚ùì Repeat Help</div>
        <div class="help-item">
            <span class="help-gesture">HOLD 2 SEC</span>
            <span class="help-or">or say</span>
            <span class="help-voice">"Help"</span>
        </div>
        
        <div class="help-section">üõë Stop / Pause</div>
        <div class="help-item">
            <span class="help-gesture">‚Äî</span>
            <span class="help-or">say</span>
            <span class="help-voice">"Stop" or "Pause"</span>
        </div>
        
        <div class="help-section">ü§ñ Switch AI Provider</div>
        <div class="help-item">
            <span class="help-gesture">‚Äî</span>
            <span class="help-or">say</span>
            <span class="help-voice">"Use GPT" / "Use Claude" / "Use both"</span>
        </div>
        
        <div class="help-buttons">
            <button class="help-btn tap" id="helpTap">TAP TO START</button>
            <button class="help-btn voice" id="helpVoice">üé§ SAY "START"</button>
        </div>
    </div>
    
    <div class="app">
        <video id="video" autoplay playsinline muted></video>
        
        <div class="touch-area" id="touchArea">
            <div class="zone zone-top" id="zoneTop">
                <div class="zone-label">TAP HERE<br>DESCRIBE AREA</div>
                <div class="zone-voice">or say "What's around"</div>
            </div>
            <div class="zone zone-middle">
                <div class="direction left" id="hintLeft">‚Üê</div>
                <div class="direction right" id="hintRight">‚Üí</div>
                <div class="status-area">
                    <div class="status-circle safe" id="status">‚úì</div>
                    <div class="listening-indicator" id="listeningIndicator">üé§ Listening...</div>
                </div>
            </div>
            <div class="zone zone-bottom" id="zoneBottom">
                <div class="zone-label">TAP HERE<br>IS IT SAFE?</div>
                <div class="zone-voice">or say "Is it safe"</div>
            </div>
        </div>
        
        <div class="mic-hint" id="micHint">üé§ Say a command anytime</div>
    </div>

    <!-- TensorFlow.js + COCO-SSD -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    
    <script>
    const CONFIG = {
        WORKER_URL: "https://guidedog.kpremks.workers.dev",
        ZONES: { immediate: 0.8, close: 1.5, awareness: 3.0 },
        CRITICAL: ["car", "bus", "truck", "motorcycle", "bicycle", "train"],
        DANGER: ["person", "dog", "cat", "horse"],
        WARNING: ["chair", "bench", "couch", "bed", "dining table", "toilet", "refrigerator", "potted plant"]
    };
    
    const state = {
        model: null,
        video: null,
        isRunning: false,
        isPaused: false,
        detections: [],
        lastVoice: 0,
        lastVibrate: 0,
        touchStart: { x: 0, y: 0, time: 0 },
        lastTap: 0,
        longPressTimer: null,
        audioCtx: null,
        recognition: null,
        isListening: false,
        continuousListening: true,
        // AI provider tracking
        aiProvider: 'race', // 'openai', 'anthropic', or 'race' (try both)
        aiStats: { openai: { success: 0, fail: 0, avgTime: 0 }, anthropic: { success: 0, fail: 0, avgTime: 0 } }
    };
    
    // ========== SPEECH OUTPUT ==========
    function speak(text, interrupt = true) {
        if (!text) return;
        
        // Pause recognition while speaking to avoid feedback
        stopListening();
        
        try {
            if (interrupt) speechSynthesis.cancel();
            const u = new SpeechSynthesisUtterance(text);
            u.rate = 0.95;
            u.onend = () => {
                // Resume listening after speaking
                setTimeout(() => {
                    if (state.continuousListening && state.isRunning && !state.isPaused) {
                        startListening();
                    }
                }, 300);
            };
            speechSynthesis.speak(u);
            state.lastVoice = Date.now();
        } catch (e) {}
    }
    
    // ========== SPEECH RECOGNITION (Voice Commands) ==========
    function initSpeechRecognition() {
        try {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                console.log('Speech recognition not supported');
                return;
            }
            
            state.recognition = new SpeechRecognition();
            state.recognition.continuous = false;
            state.recognition.interimResults = false;
            state.recognition.lang = 'en-US';
            
            state.recognition.onresult = (event) => {
                const text = event.results[0][0].transcript.toLowerCase().trim();
                console.log('üé§ Heard:', text);
                handleVoiceCommand(text);
            };
            
            state.recognition.onend = () => {
                state.isListening = false;
                updateListeningUI(false);
                
                // Restart listening if continuous mode
                if (state.continuousListening && state.isRunning && !state.isPaused) {
                    setTimeout(startListening, 500);
                }
            };
            
            state.recognition.onerror = (e) => {
                state.isListening = false;
                updateListeningUI(false);
                
                // Restart on most errors
                if (e.error !== 'not-allowed' && state.continuousListening && state.isRunning) {
                    setTimeout(startListening, 1000);
                }
            };
            
            console.log('Speech recognition initialized');
        } catch (e) {
            console.error('Speech recognition error:', e);
        }
    }
    
    function startListening() {
        if (!state.recognition || state.isListening) return;
        
        try {
            state.recognition.start();
            state.isListening = true;
            updateListeningUI(true);
        } catch (e) {
            state.isListening = false;
        }
    }
    
    function stopListening() {
        if (!state.recognition) return;
        
        try {
            state.recognition.stop();
            state.isListening = false;
            updateListeningUI(false);
        } catch (e) {}
    }
    
    function updateListeningUI(listening) {
        const indicator = document.getElementById('listeningIndicator');
        const status = document.getElementById('status');
        
        if (listening) {
            indicator.classList.add('active');
        } else {
            indicator.classList.remove('active');
        }
    }
    
    function handleVoiceCommand(text) {
        vibrate([30]);
        
        // Help commands
        if (text.includes('help') || text.includes('how') || text.includes('what can')) {
            showHelp();
            return;
        }
        
        // Start command (from help screen)
        if (text.includes('start') || text.includes('begin') || text.includes('go')) {
            if (document.getElementById('help').classList.contains('visible')) {
                hideHelp();
                return;
            }
        }
        
        // Stop/Pause commands
        if (text.includes('stop') || text.includes('pause') || text.includes('quiet')) {
            state.isPaused = true;
            speak('Navigation paused. Say resume to continue.');
            return;
        }
        
        // Resume commands
        if (text.includes('resume') || text.includes('continue') || text.includes('unpause')) {
            state.isPaused = false;
            speak('Navigation resumed.');
            return;
        }
        
        // Describe / What's around
        if (text.includes('around') || text.includes('describe') || text.includes('what') && text.includes('see') || 
            text.includes('where am') || text.includes('surroundings')) {
            describeScene();
            return;
        }
        
        // Safety check
        if (text.includes('safe') || text.includes('clear') || text.includes('walk') || 
            text.includes('go ahead') || text.includes('can i go')) {
            checkSafety();
            return;
        }
        
        // Left side
        if (text.includes('left')) {
            checkDirection('left');
            return;
        }
        
        // Right side
        if (text.includes('right')) {
            checkDirection('right');
            return;
        }
        
        // Ahead / Front
        if (text.includes('ahead') || text.includes('front') || text.includes('forward')) {
            checkDirection('ahead');
            return;
        }
        
        // AI Scan
        if (text.includes('scan') || text.includes('analyze') || text.includes('detail') || 
            text.includes('stair') || text.includes('door') || text.includes('ai')) {
            detailedScan();
            return;
        }
        
        // Switch AI provider commands
        if (text.includes('use openai') || text.includes('use gpt') || text.includes('switch to openai')) {
            state.aiProvider = 'openai';
            speak('Switched to OpenAI GPT-4.');
            return;
        }
        
        if (text.includes('use claude') || text.includes('use anthropic') || text.includes('switch to claude')) {
            state.aiProvider = 'anthropic';
            speak('Switched to Anthropic Claude.');
            return;
        }
        
        if (text.includes('use both') || text.includes('use fastest') || text.includes('auto') || text.includes('race')) {
            state.aiProvider = 'race';
            speak('Using both AI providers. Will use fastest response.');
            return;
        }
        
        if (text.includes('which ai') || text.includes('what ai') || text.includes('current ai')) {
            const provider = state.aiProvider === 'race' ? 'both, using fastest' : state.aiProvider;
            speak(`Currently using ${provider}.`);
            return;
        }
        
        // Repeat last
        if (text.includes('repeat') || text.includes('again') || text.includes('what did you say')) {
            // Re-describe
            describeScene();
            return;
        }
        
        // Unknown command - be helpful
        speak('I heard ' + text + '. Try saying: what\'s around, is it safe, or scan.');
    }
    
    // ========== VIBRATION ==========
    function vibrate(pattern) {
        const now = Date.now();
        if (now - state.lastVibrate < 300) return;
        state.lastVibrate = now;
        try { navigator.vibrate?.(pattern); } catch (e) {}
    }
    
    // ========== AUDIO ==========
    function initAudio() {
        try { state.audioCtx = new (window.AudioContext || window.webkitAudioContext)(); } catch (e) {}
    }
    
    function playTone(freq, dur, pan = 0) {
        if (!state.audioCtx) return;
        try {
            if (state.audioCtx.state === 'suspended') state.audioCtx.resume();
            const osc = state.audioCtx.createOscillator();
            const gain = state.audioCtx.createGain();
            const panner = state.audioCtx.createStereoPanner();
            osc.frequency.value = freq;
            gain.gain.setValueAtTime(0.3, state.audioCtx.currentTime);
            gain.gain.exponentialRampToValueAtTime(0.01, state.audioCtx.currentTime + dur);
            panner.pan.value = pan;
            osc.connect(gain).connect(panner).connect(state.audioCtx.destination);
            osc.start();
            osc.stop(state.audioCtx.currentTime + dur);
        } catch (e) {}
    }
    
    // ========== AI ANALYSIS (Smart - uses best provider) ==========
    
    // Call a single provider
    async function callProvider(imageData, provider) {
        const startTime = Date.now();
        try {
            const response = await fetch(CONFIG.WORKER_URL, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ image: imageData, provider: provider })
            });
            
            const data = await response.json();
            const duration = Date.now() - startTime;
            
            if (data.result) {
                // Track success
                state.aiStats[provider].success++;
                state.aiStats[provider].avgTime = 
                    (state.aiStats[provider].avgTime * (state.aiStats[provider].success - 1) + duration) / 
                    state.aiStats[provider].success;
                return { result: data.result, provider, duration };
            } else {
                state.aiStats[provider].fail++;
                return null;
            }
        } catch (e) {
            state.aiStats[provider].fail++;
            return null;
        }
    }
    
    // Smart AI analysis - races both or uses best
    async function analyzeWithAI() {
        try {
            // Capture frame
            const canvas = document.createElement('canvas');
            canvas.width = 320;
            canvas.height = 240;
            canvas.getContext('2d').drawImage(state.video, 0, 0, 320, 240);
            const imageData = canvas.toDataURL('image/jpeg', 0.6).split(',')[1];
            
            // Determine which provider(s) to use
            const mode = state.aiProvider;
            
            if (mode === 'openai') {
                const result = await callProvider(imageData, 'openai');
                return result?.result || null;
            }
            
            if (mode === 'anthropic') {
                const result = await callProvider(imageData, 'anthropic');
                return result?.result || null;
            }
            
            // RACE MODE: Try both, use first successful response
            if (mode === 'race') {
                const results = await Promise.allSettled([
                    callProvider(imageData, 'openai'),
                    callProvider(imageData, 'anthropic')
                ]);
                
                // Get successful results
                const successes = results
                    .filter(r => r.status === 'fulfilled' && r.value?.result)
                    .map(r => r.value);
                
                if (successes.length === 0) {
                    return null;
                }
                
                // Return fastest successful result
                successes.sort((a, b) => a.duration - b.duration);
                const winner = successes[0];
                
                console.log(`üèÜ AI Winner: ${winner.provider} (${winner.duration}ms)`);
                
                // Auto-optimize: if one provider is consistently faster/better, prefer it
                const openaiScore = state.aiStats.openai.success / (state.aiStats.openai.success + state.aiStats.openai.fail + 1);
                const anthropicScore = state.aiStats.anthropic.success / (state.aiStats.anthropic.success + state.aiStats.anthropic.fail + 1);
                
                // After 5 calls, if one is clearly better (>20% difference), prefer it
                const totalCalls = state.aiStats.openai.success + state.aiStats.anthropic.success;
                if (totalCalls > 5) {
                    if (openaiScore > anthropicScore + 0.2 && state.aiStats.openai.avgTime < state.aiStats.anthropic.avgTime) {
                        console.log('üìä Auto-selecting OpenAI as preferred provider');
                        state.aiProvider = 'openai';
                    } else if (anthropicScore > openaiScore + 0.2 && state.aiStats.anthropic.avgTime < state.aiStats.openai.avgTime) {
                        console.log('üìä Auto-selecting Anthropic as preferred provider');
                        state.aiProvider = 'anthropic';
                    }
                }
                
                return winner.result;
            }
            
            return null;
        } catch (e) {
            console.error('AI analysis error:', e);
            return null;
        }
    }
    
    // ========== OBJECT DETECTION ==========
    async function detect() {
        if (!state.model || !state.video) return [];
        
        try {
            const predictions = await state.model.detect(state.video);
            
            return predictions.map(p => {
                const cx = (p.bbox[0] + p.bbox[2] / 2) / state.video.videoWidth;
                const size = Math.max(p.bbox[2], p.bbox[3]) / Math.max(state.video.videoWidth, state.video.videoHeight);
                
                let position = 'ahead';
                if (cx < 0.33) position = 'left';
                else if (cx > 0.67) position = 'right';
                
                let depth = 5.0;
                if (size > 0.5) depth = 0.5;
                else if (size > 0.35) depth = 1.0;
                else if (size > 0.2) depth = 1.5;
                else if (size > 0.1) depth = 2.5;
                else if (size > 0.05) depth = 4.0;
                
                let priority = 'info';
                if (CONFIG.CRITICAL.includes(p.class)) priority = 'critical';
                else if (CONFIG.DANGER.includes(p.class)) priority = 'danger';
                else if (CONFIG.WARNING.includes(p.class)) priority = 'warning';
                
                return { name: p.class, position, depth, priority, inPath: cx > 0.25 && cx < 0.75 };
            }).sort((a, b) => {
                const p = { critical: 0, danger: 1, warning: 2, info: 3 };
                return (p[a.priority] - p[b.priority]) || (a.depth - b.depth);
            });
        } catch (e) {
            return [];
        }
    }
    
    // ========== ACTIONS ==========
    async function describeScene() {
        vibrate([30]);
        speak('Scanning area...');
        
        // Get AI description (better quality)
        const aiResult = await analyzeWithAI();
        
        if (aiResult) {
            speak(aiResult);
            return;
        }
        
        // Fallback to local detection
        const detections = await detect();
        
        if (detections.length === 0) {
            speak('The area appears clear. No obstacles detected.');
            updateStatus('safe');
            return;
        }
        
        let desc = '';
        const ahead = detections.filter(d => d.position === 'ahead');
        const left = detections.filter(d => d.position === 'left');
        const right = detections.filter(d => d.position === 'right');
        
        if (ahead.length) desc += `${ahead[0].name} ahead, about ${ahead[0].depth.toFixed(1)} meters. `;
        if (left.length) desc += `${left[0].name} on your left. `;
        if (right.length) desc += `${right[0].name} on your right. `;
        
        speak(desc || 'Some objects detected nearby.');
    }
    
    async function checkSafety() {
        vibrate([30]);
        
        const detections = await detect();
        const inPath = detections.filter(d => d.inPath);
        
        if (inPath.length === 0) {
            vibrate([50, 30, 50]);
            speak('Path is clear. Safe to walk forward.');
            updateStatus('safe');
            return;
        }
        
        const closest = inPath[0];
        
        if (closest.depth < CONFIG.ZONES.immediate) {
            vibrate([200, 100, 200, 100, 200]);
            speak(`Stop! ${closest.name} very close! Less than 1 meter ahead!`);
            updateStatus('danger');
        } else if (closest.depth < CONFIG.ZONES.close) {
            vibrate([100, 50, 100]);
            speak(`Caution. ${closest.name} ahead, about ${closest.depth.toFixed(1)} meters. Proceed carefully.`);
            updateStatus('warning');
        } else {
            vibrate([50, 30, 50]);
            speak(`Path mostly clear. ${closest.name} detected ahead at safe distance.`);
            updateStatus('safe');
        }
    }
    
    async function checkDirection(dir) {
        vibrate([30]);
        
        const detections = await detect();
        
        if (dir === 'ahead') {
            const items = detections.filter(d => d.position === 'ahead');
            if (items.length === 0) {
                speak('Nothing directly ahead.');
            } else {
                speak(`${items[0].name} ahead, about ${items[0].depth.toFixed(1)} meters.`);
            }
            return;
        }
        
        const items = detections.filter(d => d.position === dir);
        
        // Show direction hint
        const hintEl = document.getElementById(`hint${dir.charAt(0).toUpperCase() + dir.slice(1)}`);
        if (hintEl) {
            hintEl.classList.add('active');
            setTimeout(() => hintEl.classList.remove('active'), 500);
        }
        
        if (items.length === 0) {
            speak(`Nothing detected on your ${dir}.`);
        } else {
            speak(`${items[0].name} on your ${dir}, about ${items[0].depth.toFixed(1)} meters.`);
        }
    }
    
    async function detailedScan() {
        vibrate([30]);
        speak('Running detailed AI scan. Please wait.');
        
        const result = await analyzeWithAI();
        if (result) {
            speak(result);
        } else {
            speak('Scan complete. No stairs, doors, or hazards detected.');
        }
    }
    
    // ========== STATUS ==========
    function updateStatus(status) {
        const el = document.getElementById('status');
        el.className = `status-circle ${status}`;
        el.textContent = status === 'safe' ? '‚úì' : status === 'warning' ? '!' : '‚ö†';
    }
    
    // ========== AUTO NAVIGATION ==========
    async function processNavigation() {
        if (!state.isRunning || state.isPaused) {
            setTimeout(processNavigation, 1000);
            return;
        }
        
        const detections = await detect();
        state.detections = detections;
        
        const threat = detections.find(d => d.inPath && (d.priority === 'critical' || d.priority === 'danger'));
        
        if (threat && threat.depth < CONFIG.ZONES.immediate) {
            updateStatus('danger');
            playTone(1000, 0.15, threat.position === 'left' ? -0.8 : threat.position === 'right' ? 0.8 : 0);
            vibrate([150, 80, 150]);
            
            const now = Date.now();
            if (now - state.lastVoice > 3000) {
                const dir = threat.position === 'left' ? 'right' : threat.position === 'right' ? 'left' : 'back';
                speak(`Stop! ${threat.name}! Go ${dir}!`);
            }
        } else if (threat && threat.depth < CONFIG.ZONES.close) {
            updateStatus('warning');
            playTone(700, 0.1, threat.position === 'left' ? -0.8 : threat.position === 'right' ? 0.8 : 0);
        } else {
            updateStatus('safe');
        }
        
        setTimeout(processNavigation, 500);
    }
    
    // ========== GESTURES ==========
    function setupGestures() {
        const area = document.getElementById('touchArea');
        
        area.addEventListener('touchstart', e => {
            const t = e.touches[0];
            state.touchStart = { x: t.clientX, y: t.clientY, time: Date.now() };
            state.longPressTimer = setTimeout(() => {
                vibrate([30]);
                showHelp();
            }, 2000);
        }, { passive: true });
        
        area.addEventListener('touchmove', () => {
            clearTimeout(state.longPressTimer);
        }, { passive: true });
        
        area.addEventListener('touchend', e => {
            clearTimeout(state.longPressTimer);
            
            const t = e.changedTouches[0];
            const dx = t.clientX - state.touchStart.x;
            const dy = t.clientY - state.touchStart.y;
            const duration = Date.now() - state.touchStart.time;
            
            if (duration > 1500) return;
            
            // Swipe
            if (Math.abs(dx) > 60 && Math.abs(dx) > Math.abs(dy)) {
                checkDirection(dx > 0 ? 'right' : 'left');
                return;
            }
            
            // Double tap
            const now = Date.now();
            if (now - state.lastTap < 400) {
                detailedScan();
                state.lastTap = 0;
                return;
            }
            state.lastTap = now;
            
            // Single tap zones
            const y = t.clientY / window.innerHeight;
            if (y < 0.33) {
                describeScene();
            } else if (y > 0.67) {
                checkSafety();
            }
        }, { passive: true });
    }
    
    // ========== HELP ==========
    function showHelp() {
        document.getElementById('help').classList.add('visible');
        stopListening();
        
        speak('Help guide. You can use gestures or voice commands. ' +
              'Tap top of screen or say "what\'s around" to describe area. ' +
              'Tap bottom or say "is it safe" to check path. ' +
              'Double tap or say "scan" for AI analysis. ' +
              'Swipe or say "left" or "right" to check sides. ' +
              'Say "stop" to pause, "resume" to continue. ' +
              'Tap a button or say "start" to begin.');
        
        // Start listening for "start" command
        setTimeout(() => {
            if (document.getElementById('help').classList.contains('visible')) {
                startListening();
            }
        }, 15000);
    }
    
    function hideHelp() {
        document.getElementById('help').classList.remove('visible');
        vibrate([50, 30, 50]);
        speak('BlindGuide ready. I will alert you to obstacles. Say "help" anytime to hear commands again.');
        state.isRunning = true;
        state.isPaused = false;
        processNavigation();
        
        // Start continuous listening
        setTimeout(startListening, 2000);
    }
    
    // ========== INIT ==========
    async function init() {
        state.video = document.getElementById('video');
        initAudio();
        initSpeechRecognition();
        setupGestures();
        
        document.getElementById('helpTap').addEventListener('click', hideHelp);
        document.getElementById('helpVoice').addEventListener('click', () => {
            speak('Listening for start command...');
            startListening();
        });
        
        document.getElementById('loadingText').textContent = 'Loading AI model...';
        
        try {
            state.model = await cocoSsd.load();
            console.log('Model loaded');
        } catch (e) {
            console.error('Model error:', e);
        }
        
        document.getElementById('loadingText').textContent = 'Starting camera...';
        
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment', width: { ideal: 640 }, height: { ideal: 480 } },
                audio: false
            });
            state.video.srcObject = stream;
            await state.video.play();
        } catch (e) {
            speak('Camera access required. Please allow camera and refresh.');
            return;
        }
        
        document.getElementById('loading').classList.add('hidden');
        
        // Show help on first use
        if (!localStorage.getItem('blindguide_v4')) {
            localStorage.setItem('blindguide_v4', 'true');
            showHelp();
        } else {
            speak('BlindGuide ready. Tap top to describe, tap bottom to check safety, or use voice commands.');
            state.isRunning = true;
            processNavigation();
            setTimeout(startListening, 2000);
        }
    }
    
    window.addEventListener('load', init);
    
    document.addEventListener('visibilitychange', () => {
        if (document.hidden) {
            state.isRunning = false;
            stopListening();
        } else {
            state.isRunning = true;
            processNavigation();
            if (state.continuousListening) startListening();
        }
    });
    
    if ('serviceWorker' in navigator) {
        navigator.serviceWorker.register('sw.js').catch(() => {});
    }
    </script>
</body>
</html>
